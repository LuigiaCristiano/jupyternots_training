{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17b0da73",
   "metadata": {},
   "source": [
    "# Using Python functions and community software to visualize `HDF5` <br> and `NeXus` files in the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f5e4c6-d95c-467d-ae7f-5e328ee0573d",
   "metadata": {},
   "source": [
    "This notebook has been made using the following material:\n",
    "\n",
    "H5Web project [https:/github.com/silx-kit/h5web](https:/github.com/silx-kit/h5web);\n",
    "\n",
    "[www.christopherlovell.co.uk](www.christopherlovell.co.uk);<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a7feab-16a6-4c17-95cb-1ca9a5e37837",
   "metadata": {},
   "source": [
    "\n",
    "[https://docs.h5py.org](https://docs.h5py.org) <br>\n",
    "[pythonforthelab.com/blog/how-to-use-hdf5-files-in-python](https://www.pythonforthelab.com/blog/how-to-use-hdf5-files-in-python)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c53f12a-7728-4061-a486-99cf611753a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Part 1: Creating and editing HDF5 files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3979fb-62a1-4e42-9743-5d90ae1c36ca",
   "metadata": {},
   "source": [
    "<a name=\"Index\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5c7fbd-f0fb-48af-8104-e481a0d35b81",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Content\n",
    "* [Create and display a simple HDF5 file](#Create)\n",
    "* [Add content in hierarchical structure](#Hierarchical)\n",
    "%* [call and visualize content](#explore)\n",
    "* [create links: hard, soft, relative](#link)\n",
    "* [insert compression](#compression)\n",
    "* [save as ASCII](#ascii)\n",
    "* [plotting routines](#plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf4ebd9",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name=\"Create\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd57d9a-f4fc-4968-851c-a5c221965ab8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Create and display a simple HDF5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0085f19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py, os, json\n",
    "#remove first local  copies\n",
    "filename= \"simple.h5\"\n",
    "filename1=\"simple1.h5\"\n",
    "if os.path.exists(filename):\n",
    "    os.remove(filename)\n",
    "if os.path.exists(filename1):\n",
    "    os.remove(filename1)    \n",
    "#the file is created\n",
    "\n",
    "with h5py.File(filename, \"w\") as h5file:\n",
    "    X = np.arange(-5, 5, 0.25)\n",
    "    Y = np.arange(-5, 5, 0.25)\n",
    "    Xg, Yg = np.meshgrid(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "252c1c7a-4154-45ad-bf65-77ce26a8ead3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new elements respect original notebook are some visualization\n",
    "#and alternative creation of hdf5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa2b7f09-4bdd-4bad-84ad-2aa191277508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 40) (40, 40)\n"
     ]
    }
   ],
   "source": [
    "print(Xg.shape,Yg.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e7ef5e-f9d0-4f7f-885d-b116bef3a63a",
   "metadata": {},
   "source": [
    "*Definition of new arrays of data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9ea48af-ab84-4270-bbcb-bdf17300e40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1=[np.sin(2*np.pi*f*np.sqrt(Xg**2 + Yg**2)) for f in np.arange(0.1, 1.1, 0.1)]\n",
    "d2= np.sin(np.sqrt(Xg**2 + Yg**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd922e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Closed HDF5 file>\n"
     ]
    }
   ],
   "source": [
    "print(h5file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308d93a6-ecdc-4c73-9b87-2d8fcebbbfd1",
   "metadata": {},
   "source": [
    "There are several ways to enrich the hdf5 file with content\n",
    "One is with `create_dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bbefb4b-d78e-493b-ad16-26debfb601c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf2=h5py.File(filename1,'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b500eb1e-2830-47e7-af26-e2e85c06d12b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"dataset_2\": shape (40, 40), type \"<f8\">"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf2.create_dataset('dataset_1',data=d1)\n",
    "hf2.create_dataset('dataset_2',data=d2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc463f1f-036e-4f1d-b863-909ab0eb02e7",
   "metadata": {},
   "source": [
    "Let's parse the array elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e58d62ea-e8e4-41c8-8764-5c30f0a30438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01180287 0.0554391  0.09152959 ... 0.32010572 0.96838155 0.71253099]\n",
      "[0.01180287 0.0554391  0.09152959 ... 0.32010572 0.96838155 0.71253099]\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(filename1,'r') as f_t_u:\n",
    "    t1=f_t_u['dataset_1']\n",
    "    t2=f_t_u['dataset_2']\n",
    "    print(t1[t1[:]>0.001])\n",
    "    data = t1[t1[()]>0.001]\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875d24f9-ecc3-4d9b-bee9-a9850b719f9b",
   "metadata": {},
   "source": [
    "This way we created a copy of the dataset into the RAM, the actual data are in the hard-drive\n",
    "for further manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4277d79-ca39-4c9c-8527-e40896e85758",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "693062b9-1f0d-4e30-9c15-7daa82521338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['dataset_1', 'dataset_2']>\n"
     ]
    }
   ],
   "source": [
    "print(hf2.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c716d5-1a4d-45d3-b23a-08eeb10f65a9",
   "metadata": {},
   "source": [
    "## The other method for the definition of HDF5 elements is  the direct assignment,<br> with dictionary call and direct keys definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abc7f040-353a-47c6-b6e8-160305de03eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.remove(filename1)\n",
    "with h5py.File(filename1,'w') as h5filen:\n",
    "    h5filen['one'] = d1\n",
    "    h5filen['two'] = d2\n",
    "    #h5file['oneD'] = X\n",
    "    #h5file['scalar'] = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a04f4dd0-d1ae-45e0-8b3f-1828b3c6fd39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ItemsViewHDF5(<Closed HDF5 file>)\n"
     ]
    }
   ],
   "source": [
    "print(h5filen.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8de86b-220e-478c-8e80-e21db36e9b60",
   "metadata": {
    "tags": []
   },
   "source": [
    "It is possible to update the assignment\n",
    "and to extract the elements of the hdf5 file using multiple methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4175be9d-0969-4e52-b167-f4b4a4bb632d",
   "metadata": {},
   "source": [
    "e.g. using the `get` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f85790d8-390a-4f48-a28d-069dfbd88a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "n1=hf2.get('dataset_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5d9393-171c-4cae-a75b-c649eebdc31b",
   "metadata": {},
   "source": [
    "we can convert the object to an array using `numpy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6b09c7c-f6ca-43bf-8642-e1419f7d33a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 40, 40)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n1=np.array(n1)\n",
    "n1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53e152b-dfb1-4d76-904c-77b8105642ca",
   "metadata": {},
   "source": [
    "*alternatively*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f1d4001-be96-47e7-84d1-b83ebd59701d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 40, 40)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n2=hf2['dataset_1']\n",
    "np.array(n2).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0e89f2-5bfc-4547-8519-24d7dd07dd53",
   "metadata": {},
   "source": [
    "or"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4478bb6-82ae-4f67-a1b8-ea245fdbd3d0",
   "metadata": {},
   "source": [
    "Visualize the data in the file using the call `keys()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36030d30-ff69-46ad-8fb6-0adc7a6f03b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf1=h5py.File('simple.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d323ef4-e615-4ed7-9baf-e50cb4d94e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 []>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf1.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aef780c-1deb-4984-b833-376dec7ecfd0",
   "metadata": {},
   "source": [
    "<a name=\"Hierarchical\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df57573d-6fb9-4e2e-a9ba-9f8e46bf8c3f",
   "metadata": {},
   "source": [
    "[Go back to index](#Index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a384efe-f40c-4be5-97ba-1fb6cab97db1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Introducing the hierarchical structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2f5cc1-6619-4c9b-9820-392e2367ac3e",
   "metadata": {},
   "source": [
    "*Using group function*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11e71de-b700-423f-9154-330d2881012f",
   "metadata": {},
   "source": [
    "Group can be seen as container to organize the data in the HDF5\n",
    "they are characterized by keys (names),  vakues (container elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "052ad143-ff00-42a4-9214-ec98fd9d30d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#h5file['oneD']['data']=X \n",
    "#check why it doesn't work\n",
    "if os.path.exists(filename1):\n",
    "    os.remove(filename1)\n",
    "h5file1=h5py.File(filename1,'w')\n",
    "g1=h5file1.create_group('group1')\n",
    "dg1=g1.create_dataset('data1',data=d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d28de83b-dfcf-4cf5-9ead-0841b8d7f24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ItemsViewHDF5(<HDF5 group \"/group1\" (1 members)>)\n"
     ]
    }
   ],
   "source": [
    "print(g1.items())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bf99e9b-1052-43c9-8cff-66d29edd56c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/group1\n"
     ]
    }
   ],
   "source": [
    "print(g1.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9085e83b-9cde-44da-a5d3-71519bb9c7f9",
   "metadata": {},
   "source": [
    "You can notice that the name of the group is specified by a slash \"/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca90121c-6872-4087-a2b1-57324839fe23",
   "metadata": {},
   "source": [
    "Every group is created with an hard link and is possible to explore the content using the <br>\n",
    "`keys` function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20125393-7d0a-4a7e-9486-9a29aa95658d",
   "metadata": {},
   "source": [
    "`items`,`values`,`keys` are calls to explore the groups\n",
    "The names of the objects are all strings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a54762ea-2ff2-4d56-b04b-4416e2d8b5ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "subgrp=g1.create_group(\"/group1/subgroup1\")\n",
    "#,\"textsubgroup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe01d403-36f6-474b-b26a-815a201c3c2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/group1/subgroup1\n"
     ]
    }
   ],
   "source": [
    "print(subgrp.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59412a84-c71d-4ac4-8297-c38c783d9ac4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 group \"/group1/subgroup1\" (0 members)>\n"
     ]
    }
   ],
   "source": [
    "out=h5file1['group1']['subgroup1']\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9bfd6870-d96d-4c62-8342-dbee1aae9583",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValuesViewHDF5(<HDF5 group \"/group1\" (2 members)>)\n"
     ]
    }
   ],
   "source": [
    "print(g1.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c584d2-6399-41ba-99ab-2a31340e929f",
   "metadata": {},
   "source": [
    "Many groups can be defined and many arrays associated to the groups<br>\n",
    "`del` command can be used to remove objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91634aa1-c02b-492c-9b7e-b33e16bd30b4",
   "metadata": {},
   "source": [
    "#### Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48d262df-4a5c-4720-b7d5-7c3200edf8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ItemsViewHDF5(<HDF5 group \"/group1\" (1 members)>)\n",
      "Date 1649851060.5856996\n",
      "User Me\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(filename):\n",
    "    os.remove(filename)\n",
    "os.remove(filename1)\n",
    "import time\n",
    "with h5py.File(filename1,'w') as h5file1:\n",
    "    g1=h5file1.create_group('group1')\n",
    "    dg1=g1.create_dataset('data1',data=d1)\n",
    "    print(g1.items())\n",
    "    g1.attrs['Date'] = time.time()\n",
    "    g1.attrs['User'] = 'Me'\n",
    "    for k in g1.attrs.keys():\n",
    "        print(k, g1.attrs[k])\n",
    "\n",
    "    for j in dg1.attrs.keys():\n",
    "      print(j, dg1.attrs[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "73711dcd-51a5-4018-8741-a5c11b21f127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 dataset \"metadata\": shape (), type \"|O\">\n",
      "/group1\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "metadata = {'Date': time.time(),\n",
    "                'User': 'Me',\n",
    "                'OS': os.name,}\n",
    "if os.path.exists(filename1):\n",
    "     os.remove(filename1)\n",
    "with h5py.File(filename1,'w') as h5file1:\n",
    "    g1 = h5file1.create_group('group1')\n",
    "    d = g1.create_dataset('data_1', data=d1)\n",
    "    m = g1.create_dataset('metadata', data=json.dumps(metadata))\n",
    "    print(h5file1['group1']['metadata'])\n",
    "    print(g1.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "535706ee-8e11-469d-963c-248928330fef",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filename1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[43mfilename1\u001b[49m):\n\u001b[1;32m      2\u001b[0m     os\u001b[38;5;241m.\u001b[39mremove(filename1)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m h5py\u001b[38;5;241m.\u001b[39mFile(filename1,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m hf2:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'filename1' is not defined"
     ]
    }
   ],
   "source": [
    "if os.path.exists(filename1):\n",
    "    os.remove(filename1)\n",
    "with h5py.File(filename1,'w') as hf2:\n",
    "    g1=hf2.create_group('group1')\n",
    "    dg1=g1.create_dataset('data1',data=d1)\n",
    "    print(hf2['group1'].keys())\n",
    "    subgroup = g1.create_group(\"/group1/subgroup1\")\n",
    "    subgroup.attrs['Date'] = time.time()\n",
    "    subgroup.attrs['User'] = 'Me'\n",
    "    print(hf2.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37300dd2-cd8a-4ed4-98b8-3384622128cd",
   "metadata": {},
   "source": [
    "### Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60908275-826d-40ca-925a-a5e7f1da3737",
   "metadata": {},
   "source": [
    "[Go back to index](#Index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a500d90c-92e6-4493-a271-165df8d338ae",
   "metadata": {},
   "source": [
    "<a name=\"link\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8edd9a-da63-4d29-9548-4c92db50d442",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Create links \n",
    "** Links to the dataset**\n",
    "**Links to the group**\n",
    "**hard links**\n",
    "**soft links**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81eb423-cab5-4f2f-b6d2-e154a0d6b500",
   "metadata": {},
   "source": [
    "a.Hard links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a841f80-1e05-45c4-8037-8a8d4ee9976a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid group (or file) id (invalid group (or file) ID)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhf2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rdm-training-C6iuH1vp-py3.8/lib/python3.8/site-packages/h5py/_hl/base.py:386\u001b[0m, in \u001b[0;36mKeysViewHDF5.__str__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__str__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<KeysViewHDF5 \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/anaconda/lib/python3.8/_collections_abc.py:702\u001b[0m, in \u001b[0;36mMappingView.__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__len__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 702\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mapping\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rdm-training-C6iuH1vp-py3.8/lib/python3.8/site-packages/h5py/_hl/group.py:443\u001b[0m, in \u001b[0;36mGroup.__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;129m@with_phil\u001b[39m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__len__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;124;03m\"\"\" Number of members attached to this group \"\"\"\u001b[39;00m\n\u001b[0;32m--> 443\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_objs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5g.pyx:336\u001b[0m, in \u001b[0;36mh5py.h5g.GroupID.get_num_objs\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid group (or file) id (invalid group (or file) ID)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c82c00-9392-4f4a-b350-d40de7b364ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hf2[\"data2\"]=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5868b27c-76b8-4bac-a122-acbdbce6fb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "out=hf2['data2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c2c511-48a0-4920-a5a8-0173bba164c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86d039c-4cd2-4db1-911a-4f4fd7722565",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hf2['data3']=out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bc5bcb-dff6-412a-b3f6-465ee14e50cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(hf2['data3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57981590-943d-4767-a6e2-339d60a1543f",
   "metadata": {},
   "source": [
    "b. Soft link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b540edff-d29e-4491-bcf3-8aaa52cebf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "c. External link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e1f91d-5eeb-40ff-8a6c-e31fc9879687",
   "metadata": {},
   "source": [
    "[Go back to index](#Index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b05fef-0207-4846-96ad-f80772253644",
   "metadata": {},
   "source": [
    "<a name=\"compression\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252f7d79-9b30-4a30-bbc0-ab8351c54e50",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Specify data type and  Insert compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31e370a-3297-4c40-b343-e63af4d8b063",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py,os\n",
    "filenamet=\"testdataset_sizes\"\n",
    "if os.path.exists(filenamet):\n",
    "    os.remove(filenamet)\n",
    "with h5py.File(filenamet,'w') as file_t:\n",
    "    dset_int1=file_t.create_dataset('integers',(10,),dtype='i1')\n",
    "    dset_int8=file_t.create_dataset('integers8',(10,),dtype='i8')\n",
    "    dset_complex=file_t.create_dataset('complex',(10,),dtype='c16')\n",
    "    dset_int1[0]=1200\n",
    "    dset_int8[0]=1200.1\n",
    "    dset_complex[0]=3+4j    \n",
    "    print(file_t.keys())\n",
    "    print(file_t['integers'][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a7bebf-c50d-407e-93ec-d4621210a8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.random.randn(100000)\n",
    "\n",
    "with h5py.File('integer_1_compr.hdf5', 'w') as f:\n",
    "    d = f.create_dataset('dataset', (100000,), dtype='i1', compression=\"gzip\", compression_opts=9)\n",
    "    d[:] = arr\n",
    "\n",
    "with h5py.File('integer_8_compr.hdf5', 'w') as f:\n",
    "    d = f.create_dataset('dataset', (100000,), dtype='i8', compression=\"gzip\", compression_opts=9)\n",
    "    d[:] = arr\n",
    "\n",
    "with h5py.File('float_compr.hdf5', 'w') as f:\n",
    "    d = f.create_dataset('dataset', (100000,), dtype='f16', compression=\"gzip\", compression_opts=9)\n",
    "    d[:] = arr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85c20be-2b8f-4462-9d0e-4d7ada31c927",
   "metadata": {},
   "source": [
    "<a name=\"ascii\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a05bc1-a64e-49a1-9a9e-0555c54b38e8",
   "metadata": {},
   "source": [
    "Resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e3a3ba-b298-43f5-a172-aa418c643cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('resize_dataset.hdf5', 'w') as f:\n",
    "    d = f.create_dataset('dataset', (100, ),  maxshape=(500, ))\n",
    "    d[:100] = np.random.randn(100)\n",
    "    d.resize((200,))\n",
    "    d[100:200] = np.random.randn(100)\n",
    "\n",
    "with h5py.File('resize_dataset.hdf5', 'r') as f:\n",
    "    dset = f['dataset']\n",
    "    print(dset[99])\n",
    "    print(dset[199])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fc9e8b-eef1-4efa-8dfe-07644c4ce593",
   "metadata": {},
   "source": [
    "Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0a0d55-19d2-444c-a8e3-dc4421f85692",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = f.create_dataset(\"chunked\", (1000, 1000), chunks=(100, 100))\n",
    "dset = f.create_dataset(\"autochunk\", (1000, 1000), chunks=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5512c94-d035-4d7f-92ad-ea4216233b58",
   "metadata": {},
   "source": [
    "Compression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fbd4ad-03e7-47f1-9520-f9d7599c5944",
   "metadata": {},
   "source": [
    "[Go back to index](#Index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bea636-dc2f-4b8c-9286-f07499878509",
   "metadata": {},
   "source": [
    "## 5. Save in ASCII format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d022d0e8-78eb-413f-8d8a-1a225c996ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49b44b31-e859-4fc9-99fc-c74e0980b2bb",
   "metadata": {},
   "source": [
    "[Go back to index](#Index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89957bf3-9ece-4801-a804-8acacf555b1b",
   "metadata": {},
   "source": [
    "<a name=\"plot\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fac0dc-c916-47d2-a8b9-e8b03f18db4a",
   "metadata": {},
   "source": [
    "## 6. Plotting and Visualization \n",
    "\n",
    "**Panosc software**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ee74aa0-7494-481c-8b54-4ad956e1f24c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/x-hdf5": "/home/tfoerst/hzdr/hifis-consulting-projects/training_material1/training-material/simplet.h5",
      "text/plain": [
       "<jupyterlab_h5web.widget.H5Web object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from jupyterlab_h5web import H5Web\n",
    "import numpy as np\n",
    "import h5py, os\n",
    "#remove first local  copies\n",
    "filenamet= \"simplet.h5\"\n",
    "if os.path.exists(filenamet):\n",
    "    os.remove(filenamet)\n",
    "\n",
    "with h5py.File(filenamet, \"w\") as h5file:\n",
    "    X = np.arange(-5, 5, 0.25)\n",
    "    Y = np.arange(-5, 5, 0.25)\n",
    "    Xg, Yg = np.meshgrid(X, Y)\n",
    "    h5file['threeD'] = [np.sin(2*np.pi*f*np.sqrt(Xg**2 + Yg**2)) for f in np.arange(0.1, 1.1, 0.1)]\n",
    "    h5file['twoD'] = np.sin(np.sqrt(Xg**2 + Yg**2))\n",
    "    h5file['oneD'] = X\n",
    "    h5file['scalar'] = 42\n",
    "H5Web(filenamet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692280b0-fe29-419e-b2f7-39074140cfe2",
   "metadata": {},
   "source": [
    "[Go back to index](#Index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
